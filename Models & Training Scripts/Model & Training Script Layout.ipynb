{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8ab55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training import Example\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e2a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a blank English NLP object\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "# Add the NER pipeline to the pipeline of the NLP object\n",
    "ner = nlp.create_pipe('ner')\n",
    "nlp.add_pipe(ner, last=True)\n",
    "\n",
    "# Define the labels that the NER model will recognize\n",
    "labels = ['PERSON', 'ORG', 'GPE']\n",
    "\n",
    "# Add the labels to the NER model\n",
    "for label in labels:\n",
    "    ner.add_label(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae27ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your training data here\n",
    "TRAIN_DATA = [...] # your training data\n",
    "\n",
    "# Set up the optimizer and other training parameters\n",
    "n_iter = 100\n",
    "batch_size = 4\n",
    "dropout = 0.5\n",
    "optimizer = nlp.begin_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b28cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training loop\n",
    "for i in range(n_iter):\n",
    "    losses = {}\n",
    "    # Shuffle the training data to ensure that the model doesn't overfit to the order of the data\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    # Create batches of data using spaCy's minibatch function\n",
    "    batches = minibatch(TRAIN_DATA, size=compounding(batch_size, 32, 1.001))\n",
    "    for batch in batches:\n",
    "        # Extract the text and annotations from the batch\n",
    "        texts, annotations = zip(*batch)\n",
    "        examples = []\n",
    "        # Convert the text and annotations into Example objects\n",
    "        for i in range(len(texts)):\n",
    "            examples.append(Example.from_dict(nlp.make_doc(texts[i]), annotations[i]))\n",
    "        # Update the NER model with the examples\n",
    "        nlp.update(examples, sgd=optimizer, drop=dropout, losses=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the loss every 10 iterations\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Loss at iteration {i}: {losses['ner']}\")\n",
    "\n",
    "# Save the trained NER model to disk\n",
    "nlp.to_disk('/path/to/ner_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
